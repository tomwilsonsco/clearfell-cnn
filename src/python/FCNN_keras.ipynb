{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.merge import merge\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "from osgeo import gdal\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep NFI Map\n",
    "nfi = gpd.read_file('https://opendata.arcgis.com/datasets/d3d7bfba1cba4a3b83a948f33c5777c0_0.geojson')\n",
    "nfi = nfi[nfi['CATEGORY']=='Woodland']\n",
    "nfi = nfi[nfi['IFT_IOA'].isin(['Broadleaved','Conifer','Mixed mainly broadleaved','Mixed mainly conifer'])]\n",
    "nfi = nfi.to_crs('EPSG:27700')\n",
    "with rio.open(img_file) as r:\n",
    "    minx, miny, maxx, maxy= r.bounds\n",
    "img_extent = gpd.GeoDataFrame(geometry=[box(minx, miny, maxx, maxy)], crs='EPSG:27700')\n",
    "use_nfi = gpd.overlay(nfi, img_extent, how='intersection')\n",
    "use_nfi.to_file('../../data/nfi_woodland_scot1.shp', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf = gpd.read_file('../../data/chip_grid.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = gpd.read_file('../../data/nfi_woodland_scot1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearfell = gpd.read_file('../../data/Scot1_felledSCDBonly.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = '../../data/scot1MedianJuly2018.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = gpd.overlay(grid_gdf, forest, how='intersection')\n",
    "intersection = gpd.overlay(intersection, clearfell, how = 'intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_use = grid_gdf[grid_gdf['location'].isin(intersection['location'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_use=grid_use[['location','geometry']]\n",
    "grid_list = grid_use['location'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid in grid_list:\n",
    "    row = grid_use[grid_use['location']==grid]\n",
    "    forest_polys = gpd.overlay(row, forest, how='intersection')\n",
    "    with rio.open(img_file) as r:\n",
    "        img_arr, trans = mask(r, row['geometry'], crop=True)\n",
    "        out_meta = r.meta\n",
    "    forest_img = rasterize(forest_polys['geometry'], transform=trans, out_shape=(img_arr.shape[1], img_arr.shape[2]))\n",
    "    forest_img = np.expand_dims(forest_img, axis=0)\n",
    "    img_arr = np.vstack([img_arr, forest_img])\n",
    "    out_meta.update(count=img_arr.shape[0], width=img_arr.shape[1], height=img_arr.shape[2], transform=trans)\n",
    "    if not os.path.exists('../../data/chips'):\n",
    "        os.makedirs('../../data/chips')\n",
    "    with rio.open(f'../../data/chips/s1_chip_{row.iloc[0,0]}.tif', 'w', **out_meta) as f:\n",
    "            f.write(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_s1_bands(img_arr):\n",
    "    scale_dict = {0:(-20,-5),1:(-25,-10),2:(0,15),3:(-20,-5),4:(-25,-10),5:(0,15)}\n",
    "    for i in range(6):\n",
    "        min = scale_dict[i][0]\n",
    "        max = scale_dict[i][1]\n",
    "        img_arr[i][img_arr[i]<min]=min\n",
    "        img_arr[i][img_arr[i]>max]=max\n",
    "        img_arr[i]=img_arr[i]/max\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs= [f\"../../data/chips/{f}\" for f in os.listdir('../../data/chips') if f.endswith('.tif')]\n",
    "\n",
    "def read_img(img):\n",
    "    with rio.open(img) as f:\n",
    "        return f.read()\n",
    "\n",
    "img_features = [read_img(f) for f in tifs]\n",
    "\n",
    "img_features = [scale_s1_bands(f) for f in img_features]\n",
    "\n",
    "img_features = [reshape_as_image(i) for i in img_features]\n",
    "\n",
    "all_imgs = np.stack(img_features, axis=0)\n",
    "\n",
    "np.savez_compressed('../../data/all_img_chips', all_imgs=all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = shuffle(all_imgs)\n",
    "train, valid = train_test_split(all_imgs)\n",
    "\n",
    "#Convert the numpy arrays to tensorflow for each function to put into batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train[:,:,:,:6], train[:,:,:,6]))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((valid[:,:,:,:6], valid[:,:,:,6]))\n",
    "\n",
    "train_dataset = train_dataset.batch(16)\n",
    "validation_dataset = validation_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\treturn encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "\tencoder = conv_block(input_tensor, num_filters)\n",
    "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "\treturn encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\treturn decoder\n",
    "\n",
    "def get_model():\n",
    "\tinputs = layers.Input(shape=[256,256,6]) # 256\n",
    "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
    "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
    "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
    "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
    "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
    "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
    "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
    "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
    "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
    "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
    "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
    "\toutputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
    "\n",
    "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizers.get('adam'), \n",
    "\t\tloss=losses.get('binary_crossentropy'),\n",
    "\t\tmetrics=[metrics.get(metric) for metric in ['Precision','Recall']])\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "history = model.fit(train_dataset, epochs=10, batch_size=16, validation_data = validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_img(pred_arr, threshold=0.5):\n",
    "    return np.where(pred_arr>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, valid.shape[0])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(valid[random_idx,:,:,6])\n",
    "axarr[0].set_title('training')\n",
    "axarr[1].imshow(classify_img(results[random_idx]))\n",
    "axarr[1].set_title('predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_clipped(poly, img):\n",
    "    with rio.open(img) as r:\n",
    "        return mask(r, poly, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_chips(cnn_model, grid_gdf, source_img):\n",
    "    if not os.path.exists('../../data/chip_res'):\n",
    "        os.mkdir('../../data/chip_res')\n",
    "    grids = grid_gdf['location'].to_list()\n",
    "    for i, g in enumerate(grids):\n",
    "        row = grid_gdf[grid_gdf['location']==g]\n",
    "        with rio.open(source_img) as r:\n",
    "            img_arr, trans = mask(r, row['geometry'], crop=True)\n",
    "            out_meta = r.meta\n",
    "        img_arr = scale_s1_bands(img_arr)\n",
    "        img_arr = reshape_as_image(img_arr)\n",
    "        img_arr = np.expand_dims(img_arr, axis=0)\n",
    "        pred_img = cnn_model.predict(img_arr)\n",
    "        pred_img = classify_img(pred_img[0])\n",
    "        pred_img = pred_img.astype('uint8')\n",
    "        pred_img = reshape_as_raster(pred_img)\n",
    "        out_meta.update(count=1, width=pred_img.shape[1], height=pred_img.shape[2], transform=trans, dtype=\"uint8\")\n",
    "        with rio.open(f'../../data/chip_res/class_chip_{row.iloc[0,0]}.tif', 'w', **out_meta) as f:\n",
    "            f.write(pred_img)\n",
    "        if i % 100 ==0:\n",
    "                print(f\"processed {i} of {len(grids)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_chip_max(res_chip_dir, source_img):\n",
    "    res_chips = [f\"{res_chip_dir}/{file}\" for file in os.listdir(res_chip_dir) if file.endswith(\".tif\") and \"chip\" in file]\n",
    "    with rio.open(source_img) as f:\n",
    "        out_meta = f.meta\n",
    "        bounds = f.bounds\n",
    "    class_img, trans = merge(res_chips, method=\"max\", precision=50, bounds=bounds)\n",
    "    class_img = class_img.astype(\"uint8\")\n",
    "    out_meta.update(count=1, dtype=\"uint8\")\n",
    "    with rio.open(f\"{res_chip_dir}/classified_result.tif\", \"w\", **out_meta) as f:\n",
    "        f.write(class_img[0], indexes=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_chips(model, grid_gdf, img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_chip_max(\"../../data/chip_res/\", img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_chips = [f\"../../data/chip_res/{file}\" for file in os.listdir('../../data/chip_res') if file.endswith(\".tif\") and \"chip\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr, trans = rasterio.merge.merge(res_chips, method=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../data/chip_res/\")\n",
    "tifs = [file for file in os.listdir() if file.endswith(\".tif\") and \"chip\" in file]\n",
    "with open(\"chip_files.txt\", \"w\") as f:\n",
    "    for t in tifs:\n",
    "        f.write(t+\"\\n\")\n",
    "! gdalbuildvrt all_chips.vrt -input_file_list chip_files.txt\n",
    "add_pixel_max(\"all_chips.vrt\")\n",
    "! gdal_translate --config GDAL_VRT_ENABLE_PYTHON YES all_chips.vrt classified_result.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pixel_max(\"all_chips.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_translate -config GDAL_VRT_ENABLE_PYTHON YES all_chips.vrt classified_result.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('cow-counting': conda)",
   "metadata": {
    "interpreter": {
     "hash": "27da8624e505e03ad9bb66ce1d8ba467e54d1230e8eb058b34a44dd4225c6c88"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}